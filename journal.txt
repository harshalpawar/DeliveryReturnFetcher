New problems
r.jina.ai/hm.com finds Free shipping above ₹1999
but it's not in my scraped data
The links themselves are bad - this means jina search is bad! I need to try with brave.

For nike - jina finds ₹ 1 250.00 for all orders but gemini doesn't
This is a known issue. I need to prompt better and write clean.py

Scraped data have to go in a different data file because they fuck up my logs
It's 100% jina search issue, basically the keywords that work for hm don't work for nike and vice versa
I checked and brave works well for both nike and hm

Another problem is that nike declares a different delivery time on their policy page and product pages so this will have to be handled by the prompt. Just return the standard response.

The prompt will also need to handle memberships. Ignore delivery and return info under memberships.

Pages have a lot of noise and sites keep thinking I'm from the US

Try this idea - clean pages, extract relevant information and get final response all through Gemini by making separate API calls
Another idea - make a separate call to Gemini and have it verify the output. Also try the thinking model.
Another idea - if search fails, retry with less specific keywords instead of skipping.
Another idea - check how Jina is modifying the URLs. Store and hash the API responses.

TODO-
[x] Clean up the code
[ ] Switch to Brave Search (Critical for search accuracy).
[x] Separate Scraped Data (Quick fix to clean up logs).
[x] Optimise Gemini Prompt
[x] Include Home Page and Product Page (Some brands have the info here).
[x] Run the Pipeline for 5 Brands (Deliver something tangible).
[x] Do the 20 brand test (test on a diverse dataset)
[x] Clean up the code
[x] Excalidraw with challenges
[ ] Get a Gemini/other API key

[x] Look at the current feedback
[x] Look at the complete feedback
[x] Improve prompt
[x] Optimise Gemini config (Improves extraction accuracy).
[x] Check out structured output and any other useful options in Gemini docs
[ ] Learn statistics for calcing the accuracy/confidence
[ ] Design a system for calcing accuracy/confidence
[ ] Explore finetuning by giving it input/output examples

Another idea - since many sites link to their policy pages on the home page, scrape the home page and check if there is a policy page linked
Jina adds this - ?srsltid= - to every URL. Remove it.
keyword searching within the text combined with positional biasing is a more robust and safer strategy than URL filtering

Biggest improvements will come from - 
[ ] Using a better search engine
[x] Improving my prompt to cover as many edge cases as possible
[x] Using a reasoning LLM
[x] Crawling and find the policy pages (incase search fails)
[x] Remove URL tags
[x] Cache the scraped response

gemini split step

new idea - gemini scraped pages + human-collected info - just verify

[x] verify the code
[x] Optimise Jina config
[x] fixed urls in input
[x] use playwright for fetchpolicypages
[x] added url normalisation
[x] fix the program
    [x] URL matching problem with https:// and www
    [x] new problem with searching in fetchPolicyPages
[ ] Update sheet with new results
[ ] Implement fallback to scraping with Playwright if Jina fails
[ ] redo failed brands
[ ] Add basic url filtering with llm
[ ] Write a script to verify the cache

[x] implement verification idea
    [x] Import spreadsheet into codebase
    [x] Write a new function for verification with Gemini
    [x] Write a new prompt
    [ ] rerun the tests here

[ ] Write clean.py (split scraped data into chunks and rank them by relevance)
[ ] Test trying to split to inference step
[ ] Have Gemini verify it's own output in a seperate API request
[ ] fix the test directory
[ ] documentation, comments and make the code push-ready.

optimised jina config, added url normalisation for caching, url deduplication, playwright for fetchpolicypages, ran tests on all brands, imported human data, wrote new prompt for verification, corrected input urls

Problem in search - if 1 part fails, we skip even if other parts found urls to process

I've encountered new problems with Jina Reader, sometimes it fails to scrape the page when my playwright solution does and sometimes it cleans useful parts of the page.

Program runs fine - I'm running tests on all brands

Problem sites - prose stories, rareism, uniqlo, summer somewhere, forever 21, fabindia

Potential issue is that the cached data might be bad.

